{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_W8BBTX2dKJ"
      },
      "source": [
        "This project includes the following phases :\n",
        "- Pre-processing & Data Augmentation\n",
        "- Feature extraction\n",
        "- Classification\n",
        "\n",
        "The dataset used :    \n",
        "- In the wild data provided\n",
        "- Small dataset showcasing micro expressions in high quality : The objective of this addition is not merely having more data to train on, it's mainly to introduce real facial expressions showing micro expressions*1 that would not be visible in the first dataset.\n",
        "\n",
        "1* *Micro expressions* : Facial expressions that last **less than 0.5s** and are therefore hard to detect. They can serve to distiguish between real emotion and fake or lab made expressions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vzMDbxW7QcC"
      },
      "source": [
        "#Details :\n",
        "\n",
        "### - Data Augmentation\n",
        "- Color shift\n",
        "  - YCbCr\n",
        "  - YES\n",
        "  --> compare separate training results between (YCbCr - YES - original (greyscale))\n",
        "\n",
        "### - Feature extraction\n",
        "\n",
        "0. Relevant features (Based on Business understanding) :\n",
        "  - mouth ratio to face\n",
        "  - nb of face curves\n",
        "  - curves around eyes\n",
        "  - curves around mouth\n",
        "  - curves around nose\n",
        "  - upper lip position relative to down lip : size of vertical distance between the two (relative to one lip length)\n",
        "  - eyebrows pente relative to horizontal axis\n",
        "\n",
        "\n",
        "1. Edge Detection (for curves)\n",
        "  - Prewitt\n",
        "  - Sobel is to consider\n",
        "\n",
        "2. Filters (Optional part : for optimization)\n",
        "  - Gabor filter\n",
        "  - Local Binary Pattern (LBP)\n",
        "\n",
        "\n",
        "\n",
        "### - Add microexpressions data & perform same pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmgnOCNAdA24"
      },
      "source": [
        "The following choices of techniques adopted in this project (Edge detection filters, noise reducers...) are relative to the Business, in other words;\n",
        "Emotions and facial expressions studies show that :     \n",
        "- vertical wrinkles around the nose, a small upward tilt of the upper lip, small frowning ==> associated with disgust\n",
        "- slight upwaard tilt on the sides of the mouth demonstrated with wrinkles + small wrinkles on the exterior sides of the eyes ==> indcator of genuine happiness.\n",
        "- slight upward tilt on the sides of the mouth demonstrated with wrinkles + various degrees of frowning ==> associated with sadness.\n",
        "- etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJcY_HlaiPS1",
        "outputId": "843ba89d-97a5-4399-8d19-2c8f1dba3073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS5Kv1yYgiz6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import json\n",
        "import ast\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgNaH18KHauO",
        "outputId": "3f4d4e1d-c2a2-4dc3-8d17-3dd04f04c15b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhAv6akMgofv",
        "outputId": "8e14899f-6ab3-4779-d621-428f1999f986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 1\n",
        "# This is to be executed when woring with colab with the corresponding url\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyyii_Nfgoh1"
      },
      "outputs": [],
      "source": [
        "# 2\n",
        "url = '/content/drive/MyDrive/2. Relevant Projects/1. Emotions Recognition/Dataset'  ## Colab Drive URL\n",
        "\n",
        "#url = '/kaggle/input/ferdata'    ##Kaggle url\n",
        "\n",
        "#Account 2\n",
        "#url = '/content/drive/MyDrive/1. Emotions Recognition/Dataset'  ## Colab Drive URL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI43B11eAiMz"
      },
      "outputs": [],
      "source": [
        "url_2 = '/content/drive/MyDrive/2. Relevant Projects/1. Emotions Recognition'\n",
        "train_RGB = url_2 + '/RGB'\n",
        "train_YCBR = url_2 + '/YCBR'\n",
        "#X_RGB, y_RGB, _ = load_data(train_RGB)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z34nC1HMgpwz"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GEwqPJR_Meg"
      },
      "outputs": [],
      "source": [
        "train_dir = url +'/train'\n",
        "test_dir = url + '/test'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDxf5TO1LGo0"
      },
      "source": [
        "#### Load Images as np array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onBdHbHstgxK"
      },
      "outputs": [],
      "source": [
        "def load_data(dir_path, img_size=(48,48)):\n",
        "    X = []\n",
        "    y = []\n",
        "    i = 0\n",
        "    labels = dict()\n",
        "    for path in tqdm(sorted(os.listdir(dir_path))):\n",
        "        if not path.startswith('.'):\n",
        "            labels[i] = path\n",
        "            for file in os.listdir(dir_path +'/'+ path):\n",
        "                if not file.startswith('.'):\n",
        "                    img = cv2.imread(dir_path +'/'+ path + '/' + file)\n",
        "                    X.append(img)\n",
        "                    y.append(i)\n",
        "                    i += 1\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    print(f'{len(X)} images loaded from {dir_path} directory.')\n",
        "    return X, y, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6wxvXgMVWsi"
      },
      "outputs": [],
      "source": [
        "# This is a function that loads data from a sub directory reltive to one emotion ( purpose : faster loading for testing certain functions later on and to save resources)\n",
        "\n",
        "def load_data_One_Emotion(Sub_dir_path, img_size=(48,48)):\n",
        "    X = []\n",
        "    y = []\n",
        "    i = 0\n",
        "    labels = dict()\n",
        "\n",
        "    for file in os.listdir(Sub_dir_path ):\n",
        "        if not file.startswith('.'):\n",
        "            img = cv2.imread(Sub_dir_path +'/' + file)\n",
        "            X.append(img)\n",
        "            y.append(i)\n",
        "            i += 1\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    print(f'{len(X)} images loaded from {Sub_dir_path} directory.')\n",
        "    return X, y, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GeGeWMit0EM",
        "outputId": "e81453c2-3fdb-4381-e4b0-d054f8067470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "436 images loaded from /content/drive/MyDrive/2. Relevant Projects/1. Emotions Recognition/Dataset/train/disgust directory.\n"
          ]
        }
      ],
      "source": [
        "Sub_train_dir = url +'/train/disgust'   # Change emotion according to subdirectory, chosen disgust beacause it's the dataset with the least samples.\n",
        "X_train_Emotion, y_train_Emotion, _ = load_data(Sub_train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUo-90h2cEGH",
        "outputId": "40611eab-e39d-4c21-8d48-324fbaef58f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [09:35<00:00, 82.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28779 images loaded from /content/drive/MyDrive/2. Relevant Projects/1. Emotions Recognition/Dataset/train directory.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train, labels_tr = load_data(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGWe8N4tiPS4"
      },
      "outputs": [],
      "source": [
        "X_test, y_test,labels_ts = load_data(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1LdP5znVjtU"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbN05xeZiPS4",
        "outputId": "07c06a35-44eb-4f27-cd5d-b248d1aab1d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'angry',\n",
              " 4005: 'disgust',\n",
              " 4441: 'fear',\n",
              " 8548: 'happy',\n",
              " 15763: 'neutral',\n",
              " 20738: 'sad',\n",
              " 25588: 'surprise'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8bwgR0jiPS5"
      },
      "outputs": [],
      "source": [
        "# Function to count values of each emotion in the dataset ( separately for train & test data )\n",
        "\n",
        "def count_values(labels_dict,X_data) :\n",
        "    count = {}\n",
        "    i = 0\n",
        "    L=[]\n",
        "    for key,value in labels_dict.items() :\n",
        "        L.append(key)\n",
        "    L.append(X_data.shape[0])\n",
        "    for value in labels_dict.values() :\n",
        "        count[value] = L[i+1]-L[i]\n",
        "        i+=1\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YwtZhiPiPS5",
        "outputId": "5de008e5-f10d-4ae7-bc28-f51c9b4b987a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'angry': 4005,\n",
              " 'disgust': 436,\n",
              " 'fear': 4107,\n",
              " 'happy': 7215,\n",
              " 'neutral': 4975,\n",
              " 'sad': 4850,\n",
              " 'surprise': 3191}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Nb_train=count_values(labels_tr,X_train)\n",
        "Nb_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3Z_BiSOglqs"
      },
      "source": [
        "The data is unbalanced :\n",
        "- disgust training data is 1/10 less than the other emotions' datasets.\n",
        "- Happy has the maximum training data.\n",
        "\n",
        "==> This should cause biased results in identifying those two emotions later in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJSrtBvfiPS5"
      },
      "outputs": [],
      "source": [
        "Nb_test=count_values(labels_ts,X_test)\n",
        "Nb_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54JnLrAumPoH"
      },
      "outputs": [],
      "source": [
        "df_tr=pd.DataFrame.from_dict(Nb_train, orient='index')\n",
        "df_tr = df_tr.rename(columns={0: \"Count\"})\n",
        "#df_ts=pd.DataFrame.from_dict(Nb_test, orient='index')\n",
        "#df_ts = df_ts.rename(columns={0: \"Count\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "YFQUnqTMmSAT",
        "outputId": "7877b692-d503-474f-c780-2689354574b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cdd80d38-9720-4f69-8d7f-71c09d4b1f8c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>angry</th>\n",
              "      <td>4005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>4107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <td>7215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>4975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>4850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>3191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdd80d38-9720-4f69-8d7f-71c09d4b1f8c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdd80d38-9720-4f69-8d7f-71c09d4b1f8c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdd80d38-9720-4f69-8d7f-71c09d4b1f8c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bed06e87-0752-4666-9e01-64d2bddecd3d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bed06e87-0752-4666-9e01-64d2bddecd3d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bed06e87-0752-4666-9e01-64d2bddecd3d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_16060a88-cfbc-4d2a-a5c2-b106f45b283d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_tr')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_16060a88-cfbc-4d2a-a5c2-b106f45b283d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_tr');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Count\n",
              "angry      4005\n",
              "disgust     436\n",
              "fear       4107\n",
              "happy      7215\n",
              "neutral    4975\n",
              "sad        4850\n",
              "surprise   3191"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "KCDYqXF6mSpy",
        "outputId": "c4d171f5-847e-4820-98b7-62ab92325d58"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4d704846-edcc-4afe-8785-f9ea4de93460\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>angry</th>\n",
              "      <td>958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>1044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <td>1774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>1247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d704846-edcc-4afe-8785-f9ea4de93460')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d704846-edcc-4afe-8785-f9ea4de93460 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d704846-edcc-4afe-8785-f9ea4de93460');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3f8fe68-f569-487e-ab24-5abd844f1448\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3f8fe68-f569-487e-ab24-5abd844f1448')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3f8fe68-f569-487e-ab24-5abd844f1448 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1a0d200f-2c77-4237-83a8-950559fe0e34\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_ts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1a0d200f-2c77-4237-83a8-950559fe0e34 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_ts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Count\n",
              "angry       958\n",
              "disgust     111\n",
              "fear       1044\n",
              "happy      1774\n",
              "neutral    1243\n",
              "sad        1247\n",
              "surprise    831"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MtkmQF8nNXk",
        "outputId": "09bdced3-3a6a-4377-e5c0-57e684770b25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "angry        958\n",
              "disgust      111\n",
              "fear        1044\n",
              "happy       1774\n",
              "neutral     1243\n",
              "sad         1247\n",
              "surprise     831\n",
              "Name: Count, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ts.iloc[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "9g-i8AD2VmWE",
        "outputId": "c411579f-a2e7-4656-a31b-ed8c2bf29d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualiizing one specific picture by index\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.imshow(X_train[28000])\n",
        "print(y_train[28000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX_C0VsrqIBb",
        "outputId": "13720855-0bfb-45fc-a75f-5c8888daafc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'angry',\n",
              " 4005: 'disgust',\n",
              " 4441: 'fear',\n",
              " 8548: 'happy',\n",
              " 15763: 'neutral',\n",
              " 20738: 'sad',\n",
              " 25588: 'surprise'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JRYH2okYAyc"
      },
      "outputs": [],
      "source": [
        "# This functions plots a set of pictures from the dataset with their label, it plots 50 pictures by default\n",
        "\n",
        "def plot_samples(X, y, labels_dict, n=50):\n",
        "    \"\"\"\n",
        "    Creates a gridplot for desired number of images (n) from the specified set\n",
        "    \"\"\"\n",
        "    for index in range(len(labels_dict)):\n",
        "        imgs = X[np.argwhere(y == index)][:n]\n",
        "        j = 10\n",
        "        i = int(n/j)\n",
        "\n",
        "        plt.figure(figsize=(15,6))\n",
        "        c = 1\n",
        "        for img in imgs:\n",
        "            plt.subplot(i,j,c)\n",
        "            plt.imshow(img[0])\n",
        "\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            c += 1\n",
        "        plt.suptitle('Emotion: {}'.format(labels_dict[index]))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve6cdpvSPMI7",
        "outputId": "74c61930-005d-4548-e090-ef8e3a9e567b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    0,     1,     2, ..., 28776, 28777, 28778])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(labels_tr)\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuF6f2grKXHx"
      },
      "outputs": [],
      "source": [
        "plot_samples(X_train, y_train, labels_tr, n=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MPhDw2Jh1Am"
      },
      "source": [
        "# I. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGpkw_4hio9R"
      },
      "source": [
        "## 0.Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzPb7aRbiuen"
      },
      "outputs": [],
      "source": [
        "X_train= X_train/255.\n",
        "#X_test = X_test/255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1dNidnhfVsd"
      },
      "source": [
        "## 1. Noise reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_crjx75nqA7k"
      },
      "source": [
        "### 1.1. Image path generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92DokNdiBGSp"
      },
      "outputs": [],
      "source": [
        "def img_path(dir_path, img_size=(48,48)) : # returns an array of image paths\n",
        "    X_img_names = []\n",
        "    labels = dict()\n",
        "    for path in tqdm(sorted(os.listdir(dir_path))):\n",
        "        print(path)\n",
        "        if not path.startswith('.'):\n",
        "              for file in os.listdir(dir_path +'/'+ path):\n",
        "                if not file.startswith('.'):\n",
        "                    X_img_names.append(dir_path +'/'+ path + '/' + file)\n",
        "\n",
        "    X_img_names = np.array(X_img_names)\n",
        "    return X_img_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJIlQJh4CmBP",
        "outputId": "beb51ba3-764f-4750-87b4-4bd1abac5db0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angry\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 1/7 [00:32<03:12, 32.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "disgust\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 2/7 [00:35<01:17, 15.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fear\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 4/7 [01:07<00:41, 13.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "happy\n",
            "neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 5/7 [01:39<00:41, 20.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sad\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [02:14<00:00, 19.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "surprise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "X_img_names = img_path(train_dir, img_size=(48,48))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpuY6iFcJwOA"
      },
      "source": [
        "## 1.2. Gaussian filter\n",
        "**The Gaussian filter was chosen, because :**\n",
        "\n",
        "For every pixel, it gives maximum weight to the pixel at hand, and exponentially decaying weights for surrounding values according to how far they are from the central pixel being treated,\n",
        "which is a very logical way of smoothing out the pictures without creating extremes or associating non representative values to a pixel. (unlike averaging out or taking the maximum value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLUOZMXxqFn1"
      },
      "outputs": [],
      "source": [
        "def Gaussian_filter(X_img_names) : # returns array of Gaussian filtered images and saves them to a designated drive folder\n",
        "    X_filtered = []\n",
        "    x_Gauss_names = []\n",
        "    url_Gauss_img=\"/content/drive/MyDrive/2. Relevant Projects/1. Emotions Recognition/Gauss\"\n",
        "\n",
        "    for path in X_img_names :\n",
        "      img = cv2.imread(path)\n",
        "      dst = cv2.GaussianBlur(img,(3,3),cv2.BORDER_DEFAULT)\n",
        "\n",
        "      #only execute first time to save pictures to drive\n",
        "\n",
        "      cv2.imwrite(url_Gauss_img+f\"{path[81:]}\",dst)\n",
        "\n",
        "      #X_filtered.append(dst)\n",
        "\n",
        "    #X_filtered = np.array(X_filtered)\n",
        "    #return X_filtered\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6BgtMQwCt6f2",
        "outputId": "6f1a4d0f-c7d5-43cf-c4c5-c3c66fff3036"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/fear/Training_76291570.jpg'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_img_names[4700][81:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2ReGgEPiqQv"
      },
      "outputs": [],
      "source": [
        "#x_filtered_Gauss =\n",
        "Gaussian_filter(X_img_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Run2KGxJ_jG"
      },
      "outputs": [],
      "source": [
        "plot_samples(x_filtered_Gauss, y_train, labels_tr, n=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av8X0BaDC85k"
      },
      "outputs": [],
      "source": [
        "# Show one specific example by index\n",
        "'''\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.imshow(x_filtered_Gauss[5000])\n",
        "plt.imshow(X_train[5000])\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw6Lgc3GevVa"
      },
      "source": [
        "## 2. Feature Extraction\n",
        "\n",
        "2 types of methods exist :\n",
        "- **The appearance feature extraction methods** : *Gabor filter , Local Binary Pattern (LBP) , Histogram of Oriented Gradients(HOG)*\n",
        "are applied on the totality of the face image.\n",
        "- **The geometric feature-based methods** : commonly exploit landmark points in order to calculate geometric distances between face regions.\n",
        "\n",
        "\n",
        "  --> Research has concluded that **appearance feature-based techniques** achieved better results in terms of accuracy than geometric methods, therfore, we will adopt the first type methods.\n",
        "\n",
        "  -------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szQbFbWjXu1G"
      },
      "source": [
        "### 1.1.Edge Detection :\n",
        "Among existing edge detection algorithms, we find canny, sobel, Scharr, Prewitt ...\n",
        "These operators have been discarded for the following reasons :\n",
        "- **Canny** : it only keeps sharp edges and thins down the result, which won't work well in our case since the pictures are low quality and the wrinkles won't be that visible as opposed to more contrasted pixels (eyes and mouth relative to face will be the most contrasted).\n",
        "- **Sobel** : Sobel is usually used on RGB colors and performs grayscaling, whereas our dataset is already in grayscale, further grayscaling it will reduce contrast.\n",
        "\n",
        "=> Chosen operator : **Prewitt** : it avoids all the previous inadequecies, and includes a GaussBlurring effect.\n",
        "Another considered operator : **Scharr**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-VqNzdWijmj"
      },
      "source": [
        "- **Horizontal Edges** : Mouth - Eyes related\n",
        "- **Vertical Edges** : Nose around wrinkles : (indicator of disgust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EVhZXG1yT9G"
      },
      "outputs": [],
      "source": [
        "def Prewitt(X_img_names) :\n",
        "  X_Prewitt = []\n",
        "\n",
        "  #when saving to drive on colab\n",
        "  url_edge=\"/content/drive/MyDrive/2. Relevant Projects/1. Emotions Recognition/Edge_Prewitt/\"\n",
        "\n",
        "  if 2 != 3 :\n",
        "    kernelx = np.array([[-1,0,1],[-1,0,1],[-1,0,1]]) # filter to detect the vertical edges\n",
        "    kernely = np.array([[1,1,1],[0,0,0],[-1,-1,-1]]) # filter to detect the horizontal edges\n",
        "\n",
        "    for path in X_img_names :\n",
        "      if path[82]=='a':\n",
        "        img = cv2.imread(path)\n",
        "        img = img/255\n",
        "        prewitt_vertical = cv2.filter2D(src=img, ddepth= -1, kernel=kernelx)\n",
        "        prewitt_horizontal = cv2.filter2D(src=img, ddepth= -1, kernel=kernely)\n",
        "        edged_img = np.sqrt(prewitt_vertical**2 + prewitt_horizontal**2).astype(np.uint8)\n",
        "\n",
        "        # Normalize the magnitude to 0-255\n",
        "        edged_img = cv2.normalize(edged_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "        #only execute first time to save pictures to drive\n",
        "        cv2.imwrite(url_edge+f\"{path[81:]}\",edged_img)\n",
        "\n",
        "        X_Prewitt.append(edged_img)\n",
        "\n",
        "  return np.array(X_Prewitt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-hv94VndRYf"
      },
      "outputs": [],
      "source": [
        "def Prewitt_2(X_img_names) :\n",
        "    X_Prewitt = []\n",
        "    kernelx = np.array([[-1,0,1],[-1,0,1],[-1,0,1]]) # filter to detect the vertical edges\n",
        "    kernely = np.array([[1,1,1],[0,0,0],[-1,-1,-1]]) # filter to detect the horizontal edges\n",
        "    for path in X_img_names :\n",
        "      img = cv2.imread(path).astype('float64')\n",
        "      #cv2.imwrite(\"bw.jpg\",img)\n",
        "      img/=255\n",
        "      img=cv2.GaussianBlur(img,(3,3),0)\n",
        "\n",
        "      cv2.imwrite(\"gaussianblur.jpg\",img)\n",
        "\n",
        "      prewitt_vertical=cv2.filter2D(img, -1, kernelx)\n",
        "      prewitt_horizontal=cv2.filter2D(img, -1, kernely)\n",
        "      #prewitt_horizontal=ndimage.convolve(img, kernely)\n",
        "      edged_img = np.sqrt( np.square(prewitt_vertical) + np.square(prewitt_horizontal))\n",
        "\n",
        "      edged_img*=255\n",
        "      horizontal_edge=prewitt_horizontal*255\n",
        "      vertical_edge=prewitt_vertical*255\n",
        "\n",
        "      X_Prewitt.append(edged_img)\n",
        "    return np.array(X_Prewitt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXtCUtSNBcdC"
      },
      "outputs": [],
      "source": [
        "# Prewitt filter on orginal dataset\n",
        "X_Prewitt = Prewitt(X_img_names)\n",
        "#Prewitt(X_img_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYYGXlQ7eS9T"
      },
      "outputs": [],
      "source": [
        "X_Prewitt = Prewitt_2(X_img_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tohQBGgTQgfn",
        "outputId": "583bea78-99a4-4db1-8904-1608e5810fbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0,)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Prewitt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mPm4ZH5Qpfy",
        "outputId": "42664463-9711-4a24-d40d-0ea48f54bd84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_img_names[:10].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6AmXNzW2IKd"
      },
      "outputs": [],
      "source": [
        "# Prewitt filter on gaussian blurred dataset\n",
        "X_Prewitt_full = Prewitt()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9BRU--TVMLX",
        "outputId": "11631a87-b6af-49ff-b921-7d1ded1d3550"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [187, 187, 187],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [ 17,  17,  17],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[ 68,  68,  68],\n",
              "        [238, 238, 238],\n",
              "        [238, 238, 238],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [ 85,  85,  85],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[238, 238, 238],\n",
              "        [238, 238, 238],\n",
              "        [187, 187, 187],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [238, 238, 238],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[238, 238, 238],\n",
              "        [136, 136, 136],\n",
              "        [ 34,  34,  34],\n",
              "        ...,\n",
              "        [ 51,  51,  51],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [153, 153, 153],\n",
              "        ...,\n",
              "        [ 17,  17,  17],\n",
              "        [ 34,  34,  34],\n",
              "        [ 34,  34,  34]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [ 85,  85,  85],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [ 51,  51,  51],\n",
              "        [  0,   0,   0]]], dtype=uint8)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Prewitt[28000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "0iXWlLDTUy3e",
        "outputId": "e9a6c457-2519-457c-ad89-6d82b51dbdba"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b5899c4b712b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualiizing one specific picture by index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Prewitt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 0"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualiizing one specific picture by index\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.imshow(X_Prewitt[5])\n",
        "print(y_train[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQYFrQ0-WOT-"
      },
      "outputs": [],
      "source": [
        "plot_samples(X_Prewitt, y_train, labels_tr, n=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAr3s-u12h74"
      },
      "outputs": [],
      "source": [
        "#plot_samples(X_Prewitt_full, y_train, labels_tr, n=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv1E9DdFfME8"
      },
      "source": [
        "# II. Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgSVcCii3Isu"
      },
      "source": [
        "## Approach :\n",
        "1. We will create an RGB version of the original dataset (the RGB images won't be used for training).\n",
        "2. The RGB version will be used as an intermediary tool to create the YCbCr dataset and the YES dataset :\n",
        "- YCbCr : a default function is used to go from RGB to YCbCr\n",
        "- YES : a function is implemented to go from RGB to YES according to transformation matrix.\n",
        "3. The test results of the three color spaces will be compared.\n",
        "4. All the data generated after testing and benchmarking, will be used together in phases for training as an attempt to deliver better test results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuiE8sUb5Cx3"
      },
      "source": [
        "## 0. conversion to RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnsNxgyA47l5"
      },
      "outputs": [],
      "source": [
        "# Converts images from GrayScale --> RGB &\n",
        "# saves pictures to drive folder &\n",
        "# saves path to an array (annuled)\n",
        "\n",
        "def RGB(X_img_names) :\n",
        "    x_rgb = []\n",
        "    X_RGB_names = []\n",
        "    url_RGB=\"/content/drive/MyDrive/2. Relevant Projects/1. Emotions Recognition/RGB\"\n",
        "\n",
        "    for path in X_img_names :\n",
        "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        # Convert the image to RGB.\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        #only execute first time to save pictures to drive\n",
        "        cv2.imwrite(url_RGB+f\"{path[81:]}\",image_rgb)\n",
        "\n",
        "        x_rgb.append(image_rgb)\n",
        "\n",
        "\n",
        "    return(np.array(x_rgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc-5U2O8A6SP"
      },
      "outputs": [],
      "source": [
        "x_rgb = RGB(X_img_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoVXUYY8VTN0",
        "outputId": "e82efba4-2b05-42a4-cab8-37880ed78a81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angry\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 1/7 [00:30<03:00, 30.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "disgust\n",
            "fear\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 3/7 [00:34<00:37,  9.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "happy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 4/7 [01:15<01:01, 20.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████▏  | 5/7 [01:19<00:29, 14.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sad\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [01:44<00:00, 14.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "surprise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "x_rgb_names = img_path(train_RGB, img_size=(48,48))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCfLARr2-NHG"
      },
      "outputs": [],
      "source": [
        "#plotting RGB pictures\n",
        "plot_samples(x_rgb, y_train, labels_tr, n=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz-3IVwPiBK3"
      },
      "source": [
        "## 1. Color shift\n",
        "### 1.1. YCbCr\n",
        "YCbCr Color model is specified in terms of luminance (Y channel) and chrominance (Cb and Cr channels). It segments the image into a luminous component and chrominance components. In YCbCr color model, the distribution of the skin areas is consistent across different races in the Cb and Cr color spaces. As RGB color model is light sensitive so to improve the performance of skin color clustering, YCbCr color model is used. Its chrominance components are almost independent of luminance and there is non-linear relationship between chrominance (Cb, Cr) and luminance(Y) of the skin color in the high and low luminance region.\n",
        "- **Range of Y** : [16, 235] , where 16:black | 235:white.\n",
        "- **Range of Cb and Cr** :  [16–240].\n",
        "\n",
        "The main advantage of YCbCr color model is that the influence of luminosity can be removed during processing of an image. Different plots for Y, Cb and Cr values for face and non-face pixels were plotted using the reference images and studied to find the range of Y, Cb and Cr values for the face pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF8nN3DoieGM"
      },
      "outputs": [],
      "source": [
        "def YCBR(x_rgb_names) :\n",
        "    x_YCBR = []\n",
        "    url_YCBR=\"/content/drive/MyDrive/2. Relevant Projects/1. Emotions Recognition/YCBR\"\n",
        "    i=0\n",
        "\n",
        "    for path in x_rgb_names :\n",
        "      if (path[72] == 'h') :\n",
        "        print('start')\n",
        "        if os.path.exists(path[76:]) == False :\n",
        "          print((os.path.exists(path[76:])))\n",
        "          img = cv2.imread(path)\n",
        "          image_ycbr = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "          #only execute first time to save pictures to drive\n",
        "          cv2.imwrite(url_YCBR+f\"{path[71:]}\",image_ycbr)\n",
        "          i+=1\n",
        "          x_YCBR.append(image_ycbr)\n",
        "          print(i)\n",
        "\n",
        "    return(np.array(x_YCBR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jto9PJBAxq_h",
        "outputId": "a2c221d0-d28f-473a-8dbf-437f2bba73a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Training_42892118.jpg'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_rgb_names[22000][76:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_vLS2fsiQpo"
      },
      "outputs": [],
      "source": [
        "x_YCBR = YCBR(x_rgb_names)\n",
        "# happy 5155"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI3u0DO6bQff"
      },
      "outputs": [],
      "source": [
        "x_YCBR.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5yehRg4_GmZ"
      },
      "outputs": [],
      "source": [
        "plot_samples(x_YCBR, y_train, labels_tr, n=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7xJQEyZvF-D"
      },
      "source": [
        "### 1.2. YES\n",
        "Y represents the luminance channel and E and S denote the chrominance components.\n",
        "The YES space is defined by a linear transformation of the SMPTE (Society of Motion Picture and Television Engineers).\n",
        "\n",
        "It was chosen because :     \n",
        "1. It reduces variations in chrominance due to changes in luminance : in our case, we have a few pictures of dark skinned individuals with very low luminescence, making the face and edges hardly visible for the naked eye, let alone the model.\n",
        "2. It is computationally efficient the E and S channels can be computed from R, G and B by shifting bits rather than multiplication.\n",
        "3. it is free of nonsingularities : divergent values, infinite. (nonlinear spaces may have singularities)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRb9nkfkvPas"
      },
      "source": [
        "For further information about the YES color space, ref : https://link.springer.com/article/10.1007/s11554-023-01303-w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buVXJcvGOgEa",
        "outputId": "85f12396-562d-49b9-b16f-7ae5de462b5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angry\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 1/7 [00:39<03:55, 39.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "disgust\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▊       | 2/7 [00:43<01:32, 18.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fear\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 3/7 [01:19<01:46, 26.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "happy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 4/7 [02:02<01:39, 33.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [02:03<00:00, 17.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sad\n",
            "surprise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "x_ycrb_names = img_path(train_YCBR, img_size=(48,48))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBO0_Jq8OeHn"
      },
      "outputs": [],
      "source": [
        "# This part will be realized in the next phase of the project\n",
        "\n",
        "def YES(x_ycrb_names) :\n",
        "  url_YES = \"/content/drive/MyDrive/2. Relevant Projects/1. Emotions Recognition/YES\"\n",
        "  '''\n",
        "  Filter_R = [0.253,0.684,0.063]\n",
        "  Filter_G = [0.5,-0.5,0.0]\n",
        "  Filter_B = [0.25,0.25,-0.5]\n",
        "  '''\n",
        "  x_YES = []\n",
        "\n",
        "  for path in x_ycrb_names :\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # Extract Y, Cr, and Cb channels\n",
        "    Y, Cr, Cb = cv2.split(img)\n",
        "\n",
        "    # Calculate E and S channels from Cr and Cb\n",
        "    E = 0.5 * Cr - 0.5 * Cb + 128\n",
        "    S = 0.5 * Cr + 0.5 * Cb + 128\n",
        "\n",
        "    print(Y.shape)\n",
        "    print(E.shape)\n",
        "    print(S.shape)\n",
        "\n",
        "    # Merge the Y, E, and S channels to form the YES image\n",
        "    image_YES = cv2.merge(( Y, E, S))\n",
        "    print(image_YES)\n",
        "\n",
        "    #only execute first time to save pictures to drive\n",
        "    cv2.imwrite(url_YES+f\"{path[71:]}\",image_YES)\n",
        "    x_YES.append(image_YES)\n",
        "\n",
        "  return(np.array(x_YES))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_YES = YES(x_ycrb_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdsvmP4picKS"
      },
      "source": [
        "## 2. Data augmentation for 'disgust' emotion\n",
        "We will perform image cropping and rotation and similar techniques only on the disgust dataset since it has remarkably less samples than the average of other emotions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5VpfUdAjaV3"
      },
      "outputs": [],
      "source": [
        "# ImageDataGenerator for flipping\n",
        "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=20, fill_mode='nearest')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 806819,
          "sourceId": 1382739,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30587,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
